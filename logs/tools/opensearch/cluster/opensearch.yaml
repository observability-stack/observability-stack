apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: logging-cluster
spec:
  security:
    config:
      adminCredentialsSecret:
        name: opensearch-admin-credential
      securityConfigSecret:
        name: opensearch-securityconfigsecret
    tls:
      transport:
        generate: true # Let the operator generate and sign certificates
        perNode: true
      http:
        generate: true
  dashboards:
    opensearchCredentialsSecret:
      name: "logging-cluster-admin-password"
    enable: true
    version: "2.8.0"
    replicas: 1
    # basePath: "/logs"
    # tls:
    #   enable: true
    #   generate: true
    env: {}
    resources:
      limits:
        cpu: "200m"
        memory: "512Mi"
      requests:
        cpu: "200m"
        memory: "512Mi"
  general:
    version: "2.8.0"
    serviceName: logging-cluster
    httpPort: 9200
    pluginsList: ["repository-s3", "https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.8.0.0/prometheus-exporter-2.8.0.0.zip"]
    #   - https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.9.0.0/prometheus-exporter-2.9.0.0.zip
    # monitoring:
    #   enable: true
    #   scrapeInterval: "30s"
    #   monitoringUserSecret: monitoring-user-secret
    #   pluginUrl: https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.9.0.0/prometheus-exporter-2.9.0.0.zip

    # solves vm.max_map_count errors.
    # See
    #     https://github.com/Opster/opensearch-k8s-operator/blob/main/docs/userguide/main.md#deal-with-max-virtual-memory-areas-vmmax_map_count-errors
    # and
    #     https://opensearch.org/docs/1.0/opensearch/install/important-settings/
    setVMMaxMapCount: true
  nodePools:
    - component: masters
      roles:
        - cluster_manager
      replicas: 3 # node count can depend on your use-case.
      pdb: # Pod Distruption Budget
        enable: true
        minAvailable: 3
      diskSize: 75Gi # master node disk size
      persistence:
        pvc:
          storageClass: <storageClass-name> # set your own storage class
          accessModes:
            - ReadWriteOnce
      resources:
        limits:
          cpu: "6000m"
          memory: "12Gi"
        requests:
          cpu: "2000m"
          memory: "8Gi"
    - component: data-nodes
      roles:
        - data
      replicas: 3 # node count can depend on your use-case.
      pdb: # Pod Distruption Budget
        enable: true
        minAvailable: 3
      diskSize: 1000Gi # data node disk size
      persistence:
        pvc:
          storageClass: <storageClass-name> # set your own storage class
          accessModes:
            - ReadWriteOnce
      resources:
        limits:
          cpu: "6000m"
          memory: "12Gi"
        requests:
          cpu: "2000m"
          memory: "8Gi"
